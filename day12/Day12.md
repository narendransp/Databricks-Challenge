## DAY 12 (20/01/26) â€“ MLflow Basics

Todayâ€™s focus was on understanding **MLflow**, a powerful tool for **experiment tracking and model management**, which is essential for building reproducible and production-ready machine learning workflows.

---

## What I Learned Today

* **MLflow Overview**

  * Purpose of MLflow in ML lifecycle management
  * Importance of experiment tracking and reproducibility

* **MLflow Components**

  * **MLflow Tracking** â€“ logging parameters, metrics, and artifacts
  * **MLflow Models** â€“ standardized model packaging
  * **MLflow Model Registry** â€“ model versioning and lifecycle stages
  * **MLflow UI** â€“ visual comparison of experiments

* **Experiment Tracking**

  * Creating experiments and runs
  * Tracking multiple model executions

* **Model Logging**

  * Logging parameters and metrics
  * Saving trained models as artifacts

---

## Tasks I Completed

### 1. Trained a Simple Regression Model

* Built a basic linear regression model using scikit-learn
* Split data into training and testing sets

### 2. Logged Experiment Details

* Logged model parameters
* Logged evaluation metrics (MSE, RÂ² score)
* Logged trained model using MLflow

### 3. Explored MLflow UI

* Launched MLflow UI locally
* Viewed experiment runs and metadata
* Inspected logged artifacts and metrics

### 4. Compared Multiple Runs

* Executed multiple runs with slight variations
* Compared metrics across runs using MLflow UI

---

## Key Takeaways

* MLflow simplifies experiment tracking and comparison
* Logging parameters and metrics improves reproducibility
* MLflow UI makes model evaluation more transparent
* Experiment tracking is critical for scalable ML development

---

## Hashtags

#DatabricksWithIDC
#14DaysAIChallenge
#MLflow
#MachineLearning
#ExperimentTracking
#LearningInPublic

---

## ðŸ“¸ Screenshot / Proof

![Day 12 Progress](../images/day12.png)
